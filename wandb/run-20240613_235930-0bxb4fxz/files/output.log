  0%|                                                                                                                         | 0/192 [00:00<?, ?it/s]/root/miniconda3/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")









  5%|█████▊                                                                                                          | 10/192 [02:12<39:18, 12.96s/it]









 10%|███████████▋                                                                                                    | 20/192 [04:55<39:25, 13.75s/it]
 50%|█████████████████████████████████████████████████████████▌                                                         | 2/4 [00:00<00:00,  4.73it/s]
  warnings.warn(
/root/miniconda3/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'eval_loss': 1.1705877780914307, 'eval_runtime': 1.7611, 'eval_samples_per_second': 18.17, 'eval_steps_per_second': 2.271, 'epoch': 0.31}









 16%|█████████████████▌                                                                                              | 30/192 [07:55<41:32, 15.38s/it]









 21%|███████████████████████▎                                                                                        | 40/192 [10:42<42:30, 16.78s/it]
  0%|                                                                                                                           | 0/4 [00:00<?, ?it/s]

{'loss': 1.0661, 'grad_norm': 0.24553166329860687, 'learning_rate': 0.0002571428571428571, 'epoch': 0.62}
 21%|███████████████████████▎                                                                                        | 40/192 [10:43<42:30, 16.78s/it]/root/miniconda3/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/root/miniconda3/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")









 26%|█████████████████████████████▏                                                                                  | 50/192 [13:33<50:02, 21.14s/it]









 31%|██████████████████████████████████▍                                                                             | 59/192 [15:30<29:40, 13.39s/it]
 31%|███████████████████████████████████                                                                             | 60/192 [15:43<29:13, 13.28s/it]
 75%|██████████████████████████████████████████████████████████████████████████████████████▎                            | 3/4 [00:00<00:00,  3.19it/s]
  warnings.warn(
/root/miniconda3/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")









 36%|████████████████████████████████████████▊                                                                       | 70/192 [18:33<27:32, 13.55s/it]










 42%|██████████████████████████████████████████████▋                                                                 | 80/192 [21:17<26:37, 14.26s/it]

 42%|██████████████████████████████████████████████▋                                                                 | 80/192 [21:19<26:37, 14.26s/it]
 42%|██████████████████████████████████████████████▋                                                                 | 80/192 [21:19<26:37, 14.26s/it]/root/miniconda3/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/root/miniconda3/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")









 47%|████████████████████████████████████████████████████▌                                                           | 90/192 [24:09<26:37, 15.66s/it]









 52%|█████████████████████████████████████████████████████████▊                                                     | 100/192 [27:04<29:13, 19.06s/it]
  0%|                                                                                                                           | 0/4 [00:00<?, ?it/s]

{'loss': 0.9293, 'grad_norm': 1.4048058986663818, 'learning_rate': 0.00016153846153846153, 'epoch': 1.56}
 52%|█████████████████████████████████████████████████████████▊                                                     | 100/192 [27:05<29:13, 19.06s/it]/root/miniconda3/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/root/miniconda3/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")









 57%|███████████████████████████████████████████████████████████████▌                                               | 110/192 [29:54<33:32, 24.55s/it]









 62%|██████████████████████████████████████████████████████████▊                                   | 120/192 [32:05<16:06, 13.43s/it]
 75%|█████████████████████████████████████████████████████████████████████████▌                        | 3/4 [00:00<00:00,  3.34it/s]
  warnings.warn(
/root/miniconda3/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'eval_loss': 0.8653605580329895, 'eval_runtime': 1.6943, 'eval_samples_per_second': 18.887, 'eval_steps_per_second': 2.361, 'epoch': 1.88}









 68%|███████████████████████████████████████████████████████████████▋                              | 130/192 [34:59<14:19, 13.87s/it]





